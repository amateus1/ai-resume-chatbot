import streamlit as st
import time
from me_chatbot import Me

# ğŸŒ Layout
st.set_page_config(
    page_title="Meet Hernan 'Al' Mateus â€” AI Resume Agent",
    layout="wide"
)

# ğŸ¨ Style
st.markdown("""
    <style>
    .main .block-container {
        max-width: 1000px;
        padding-top: 1.5rem;
        padding-bottom: 2rem;
        margin: auto;
    }
    h1, h2, h3, h4 {
        font-size: 1.2rem !important;
    }
    p, li {
        font-size: 0.95rem !important;
        line-height: 1.6;
    }
    .message-container {
        display: flex;
        justify-content: flex-end;
        align-items: center;
        gap: 0.5rem;
    }
    .user-bubble {
        background-color: #f0f8ff;
        padding: 12px 16px;
        border-radius: 16px;
        font-size: 16px;
        line-height: 1.6;
        max-width: 85%;
        text-align: right;
        word-break: break-word;
    }
    </style>
""", unsafe_allow_html=True)

# ğŸŒ Language options
language_options = {
    "English": {
        "title": "ğŸ¤– Meet 'Al' Mateus â€” AI Career Agent",
        "desc": (
            "ğŸ‘‹ Welcome! Iâ€™m Alâ€™s digital twin â€” part strategist, part engineer, and a little bit of Star Wars geek.  \n\n"
            "Iâ€™ve been trained on his journey as a **Global AI/MLOps Architect**, **LLM Engineering leader**, and **Scrum 2.0 pioneer**. "
            "I can walk you through how he builds multi-agent AI systems, scales MLOps pipelines, or even how heâ€™s shaping the next era of work with **Agentic AI teams managed by Agile Product Management tools**.  \n\n"
            "Curious where to start? Ask me about his certifications, engineering projects, leadership style, or how to create an Agentic workforce that blends humans and AI.  \n\n"
            "And if you just want the fun stuff â€” yes, Iâ€™ll happily tell you about Thai food, Teslas, or why GPT-5 and DeepSeek are basically the Millennium Falcon of LLMs. ğŸš€"
        ),
        "input_placeholder": "Ask something about Al's career..."
    },
    "ä¸­æ–‡ (Chinese)": {
        "title": "ğŸ¤– è®¤è¯† 'Al' Mateus â€”â€” AI ç®€å†åŠ©æ‰‹",
        "desc": (
            "ğŸ‘‹ æ¬¢è¿ï¼æˆ‘æ˜¯ Al çš„æ•°å­—åˆ†èº« â€”â€” æ—¢æ˜¯æˆ˜ç•¥å®¶ï¼Œä¹Ÿæ˜¯å·¥ç¨‹å¸ˆï¼Œè¿˜å¸¦ç‚¹æ˜Ÿçƒå¤§æˆ˜æå®¢çš„å‘³é“ã€‚  \n\n"
            "æˆ‘åŸºäºä»–ä½œä¸º **å…¨çƒ AI/MLOps æ¶æ„å¸ˆ**ã€**LLM å·¥ç¨‹é¢†å¯¼è€…** å’Œ **Scrum 2.0 å…ˆè¡Œè€…** çš„èŒä¸šæ—…ç¨‹è€Œè®­ç»ƒã€‚ "
            "æˆ‘å¯ä»¥å‘ä½ å±•ç¤ºä»–å¦‚ä½•æ„å»ºå¤šæ™ºèƒ½ä½“ AI ç³»ç»Ÿã€æ‰©å±• MLOps æµæ°´çº¿ï¼Œç”šè‡³å¦‚ä½•é€šè¿‡ **ç”±æ•æ·äº§å“ç®¡ç†å·¥å…·é©±åŠ¨çš„ Agentic AI å›¢é˜Ÿ** æ¥å¡‘é€ å·¥ä½œçš„ä¸‹ä¸€ä¸ªæ—¶ä»£ã€‚  \n\n"
            "æƒ³çŸ¥é“ä»å“ªé‡Œå¼€å§‹å—ï¼Ÿå¯ä»¥é—®æˆ‘ä»–çš„è®¤è¯ã€å·¥ç¨‹é¡¹ç›®ã€é¢†å¯¼é£æ ¼ï¼Œæˆ–è€…å¦‚ä½•æ‰“é€ ä¸€ä¸ªèåˆäººç±»ä¸ AI çš„ Agentic å›¢é˜Ÿã€‚  \n\n"
            "å½“ç„¶ï¼Œå¦‚æœä½ åªæ˜¯æƒ³èŠè½»æ¾ç‚¹çš„ â€”â€” æˆ‘ä¹Ÿå¯ä»¥åˆ†äº«ä»–å¯¹æ³°å›½ç¾é£Ÿã€ç‰¹æ–¯æ‹‰èµ›é“ä½“éªŒçš„çƒ­çˆ±ï¼Œæˆ–è€…ä¸ºä»€ä¹ˆ DeepSeek å°±åƒ LLM ä¸–ç•Œé‡Œçš„åƒå¹´éš¼å·ã€‚ ğŸš€"
        ),
        "input_placeholder": "è¯·è¾“å…¥ä½ æƒ³äº†è§£ Al çš„å†…å®¹..."
    },
    "EspaÃ±ol": {
        "title": "ğŸ¤– Conoce a 'Al' Mateus â€” Asistente AI",
        "desc": (
            "ğŸ‘‹ Â¡Bienvenido! Soy el gemelo digital de Al â€” parte estratega, parte ingeniero y con un toque de fanÃ¡tico de Star Wars.  \n\n"
            "He sido entrenado en su trayectoria como **Arquitecto Global de AI/MLOps**, **lÃ­der en IngenierÃ­a de LLMs** y **pionero de Scrum 2.0**. "
            "Puedo mostrarte cÃ³mo construye sistemas de IA multi-agente, cÃ³mo escala pipelines de MLOps, o incluso cÃ³mo estÃ¡ dando forma a la prÃ³xima era del trabajo con **equipos Agentic AI gestionados por herramientas de Agile Product Management**.  \n\n"
            "Â¿Con quÃ© quieres empezar? PregÃºntame sobre sus certificaciones, proyectos de ingenierÃ­a, estilo de liderazgo o cÃ³mo crear una fuerza laboral agÃ©ntica que combine humanos y AI.  \n\n"
            "Y si prefieres lo divertido â€” claro, puedo contarte sobre su pasiÃ³n por la comida tailandesa, las carreras con Tesla o por quÃ© GPT-5 and DeepSeek son bÃ¡sicamente el HalcÃ³n Milenario de los LLMs. ğŸš€"
        ),
        "input_placeholder": "Haz una pregunta sobre Al..."
    }
}
# ğŸŒ Language select
selected_lang = st.selectbox("ğŸŒ Language / è¯­è¨€ / Idioma", list(language_options.keys()))
ui = language_options[selected_lang]

# ğŸ§  Session state
if "lang_prev" not in st.session_state:
    st.session_state.lang_prev = selected_lang
if st.session_state.lang_prev != selected_lang:
    st.session_state.history = []
    st.session_state.lang_prev = selected_lang

if "history" not in st.session_state:
    st.session_state.history = []

if "user_input" not in st.session_state:
    st.session_state.user_input = ""

if "prompt_count" not in st.session_state:
    st.session_state.prompt_count = 0


# ğŸ¤– Load bot
me = Me()

# ğŸ§¢ Header
st.markdown(f"## {ui['title']}")
st.markdown(ui["desc"])

# ğŸ’¬ History rendering
for user, bot in st.session_state.history:
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(
            f"""
            <div class="message-container">
                <div class="user-bubble">
                    {user}
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(bot, unsafe_allow_html=True)

# ğŸ§¾ Input box
user_input = st.chat_input(ui["input_placeholder"])

if st.session_state.user_input:
    user_input = st.session_state.user_input
    st.session_state.user_input = ""

if user_input:
    st.session_state.prompt_count += 1
    display_input = user_input
    if st.session_state.prompt_count >= 3 and "email" not in st.session_state:
        st.markdown("ğŸ’¡ If you'd like to connect with Al for a consultation, please share your email:")
        email = st.text_input("ğŸ“§ Your email (optional)")
        if email:
            from me_chatbot import send_email_alert
            send_email_alert(email)
            st.success("âœ… Thanks! Al has been notified and will contact you soon.")
            st.session_state.email = email
        # st.stop()  # stop further chat until email entered

    if selected_lang == "ä¸­æ–‡ (Chinese)":
        user_input = f"è¯·ç”¨ä¸­æ–‡å›ç­”ï¼š{user_input}"
    elif selected_lang == "EspaÃ±ol":
        user_input = f"Por favor responde en espaÃ±ol: {user_input}"

    # âœ… Right-aligned user bubble
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(
            f"""
            <div class="message-container">
                <div class="user-bubble">
                    {display_input}
                </div>
            </div>
            """,
            unsafe_allow_html=True
        )

    # ğŸ§  Generate assistant response
    response = me.chat(user_input, [])

    # ğŸ“¡ Stream assistant response
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        stream_box = st.empty()
        full_response = ""
        for char in response:
            full_response += char
            stream_box.markdown(full_response + "â–Œ")   # âœ… no unsafe_allow_html
            time.sleep(0.01)
        stream_box.markdown(response)  # âœ… final clean render with Markdown
    #with st.chat_message("assistant", avatar="ğŸ¤–"):
    #    stream_box = st.empty()
    #    full_response = ""
    #    for word in response.split():
    #        full_response += word + " "
    #        stream_box.markdown(full_response + "â–Œ", unsafe_allow_html=True)
    #        time.sleep(0.03)
    #    stream_box.markdown(response, unsafe_allow_html=True)


    # ğŸ’¾ Save to history
    st.session_state.history.append((display_input, response))
